{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for Financial News - Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/dsxuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/dsxuser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/dsxuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/01/457b49d790b6c4b9720e6f9dbbb617692f6ce8afdaadf425c055c41a7416/torch-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (753.2MB)\n",
      "\u001b[K     |████████████████████████████████| 753.2MB 42kB/s  eta 0:00:011                             | 8.0MB 6.9MB/s eta 0:01:48     |█                               | 22.9MB 6.9MB/s eta 0:01:46     |█▎                              | 31.1MB 41.0MB/s eta 0:00:18     |█▋                              | 37.7MB 41.0MB/s eta 0:00:18     |███▏                            | 74.3MB 39.5MB/s eta 0:00:18��████▌                     | 247.4MB 10.8MB/s eta 0:00:47     |███████████▎                    | 265.8MB 10.8MB/s eta 0:00:46     |████████████▏                   | 286.7MB 16.2MB/s eta 0:00:29     |███████████████████▋            | 462.3MB 9.7MB/s eta 0:00:31     |████████████████████▎           | 476.7MB 9.7MB/s eta 0:00:29�█████████▍          | 503.3MB 5.5MB/s eta 0:00:46█████████████▏        | 544.7MB 44.8MB/s eta 0:00:05��        | 551.1MB 44.8MB/s eta 0:00:05��        | 557.9MB 44.8MB/s eta 0:00:05     |████████████████████████        | 564.7MB 38.1MB/s eta 0:00:05MB/s eta 0:00:03��██████▏    | 639.5MB 46.8MB/s eta 0:00:03     |███████████████████████████▎    | 641.6MB 46.8MB/s eta 0:00:03��██████████████▊   | 675.0MB 42.5MB/s eta 0:00:02██████████████████▉   | 679.5MB 42.5MB/s eta 0:00:02| 684.3MB 42.5MB/s eta 0:00:02 eta 0:00:02███████  | 704.8MB 5.3MB/s eta 0:00:10��██████████████████  | 707.6MB 5.3MB/s eta 0:00:09     |██████████████████████████████▋ | 720.3MB 41.9MB/s eta 0:00:0141.9MB/s eta 0:00:01███████████████████████████████▎| 737.0MB 5.5MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch) (1.15.4)\n",
      "Requirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch) (0.17.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.5.1\n",
      "Collecting torchtext\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 7.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchtext) (1.5.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchtext) (1.12.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchtext) (4.31.1)\n",
      "Collecting sentencepiece (from torchtext)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/e5/0366f50a00db181f4b7f3bdc408fc7c4177657f5bf45cb799b79fb4ce15c/sentencepiece-0.1.92-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 15.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchtext) (1.15.4)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchtext) (2.21.0)\n",
      "Requirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch->torchtext) (0.17.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->torchtext) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->torchtext) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->torchtext) (3.0.4)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "Successfully installed sentencepiece-0.1.92 torchtext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly.offline import iplot\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "!pip install torch\n",
    "!pip install torchtext\n",
    "import torch\n",
    "from torchtext import data\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  neutral    \n",
       "1  neutral    \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  positive   \n",
       "\n",
       "                                                                                                                                                                                                                                  title  \n",
       "0  According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .                                                                                                       \n",
       "1  Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .                                        \n",
       "2  The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .  \n",
       "3  With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .                        \n",
       "4  According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .                           "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import types\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# Credentials and the data retrieval from IBM Cloud Object Storage has been removed for security reasons.\n",
    "client_x = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='REMOVED',\n",
    "    ibm_auth_endpoint=\"REMOVED\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='REMOVED')\n",
    "\n",
    "body = client_x.get_object(Bucket='REMOVED',Key='all-data.csv')['Body']\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df = pd.read_csv(body, encoding=\"ISO-8859-1\", header=None)\n",
    "df.columns = [\"sentiment\", \"title\"]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>according gran company plan move production russia although company growing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>technopolis plan develop stage area le square meter order host company working computer technology telecommunication statement said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>international electronic industry company elcoteq laid ten employee tallinn facility contrary earlier layoff company contracted rank office worker daily postimees reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>new production plant company would increase capacity meet expected increase demand would improve use raw material therefore increase production profitability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>according company updated strategy year basware target long-term net sale growth range operating profit margin net sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  \\\n",
       "0  neutral    \n",
       "1  neutral    \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  positive   \n",
       "\n",
       "                                                                                                                                                                         title  \n",
       "0  according gran company plan move production russia although company growing                                                                                                  \n",
       "1  technopolis plan develop stage area le square meter order host company working computer technology telecommunication statement said                                          \n",
       "2  international electronic industry company elcoteq laid ten employee tallinn facility contrary earlier layoff company contracted rank office worker daily postimees reported  \n",
       "3  new production plant company would increase capacity meet expected increase demand would improve use raw material therefore increase production profitability                \n",
       "4  according company updated strategy year basware target long-term net sale growth range operating profit margin net sale                                                      "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to clean the titles\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "forbidden_words = [\"``\", \"''\", \"--\", \"'s\"]\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def lowercase(text):\n",
    "    return str(text).lower()\n",
    "\n",
    "def joinText(text):\n",
    "    return \" \".join(text)\n",
    "\n",
    "def cleanText(text):\n",
    "    text=lowercase(text)\n",
    "    # Remove words with numbers\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # Tokenize\n",
    "    text=word_tokenize(text)\n",
    "    \n",
    "    clean_text = []\n",
    "    for w in text:\n",
    "        if w not in stopword_set and w not in forbidden_words and w not in punctuation:\n",
    "            w = lemmatizer.lemmatize(w)\n",
    "            clean_text.append(w)\n",
    "\n",
    "    clean_text=joinText(clean_text)\n",
    "    return clean_text\n",
    "\n",
    "df['title'] = df['title'].map(lambda text: cleanText(text))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (Linear SVM) Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_classifier_model = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                            ('clf-svm', SGDClassifier(loss='log', penalty='l2', max_iter=1000, random_state=None))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1812, 2)\n"
     ]
    }
   ],
   "source": [
    "# Data shuffling and normalizing\n",
    "df = shuffle(df)\n",
    "df_normalized=df.groupby('sentiment').apply(lambda x: x.sample(604)).reset_index(drop=True)\n",
    "print(df_normalized.shape)\n",
    "\n",
    "# Test and validation data creation\n",
    "feature1 = df_normalized[\"title\"]\n",
    "feature2 = df_normalized[\"sentiment\"]\n",
    "\n",
    "x_training_data, x_validation_data, y_training_data, y_validation_data = train_test_split(feature1, feature2, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning:\n",
      "\n",
      "You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "\n",
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6459627329192547\n",
      "{'clf-svm__alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Trainining the model and optimizing hyperparameters\n",
    "\n",
    "parameters = {}\n",
    "parameters['clf-svm__alpha'] = [0.001, 0.0005, 0.0001]\n",
    "\n",
    "clf = GridSearchCV(sgd_classifier_model, parameters)\n",
    "clf.fit(x_training_data, y_training_data)\n",
    "print(clf.best_score_)    \n",
    "print(clf.best_params_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.67      0.69       127\n",
      "     neutral       0.60      0.69      0.64       119\n",
      "    positive       0.62      0.57      0.60       117\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       363\n",
      "   macro avg       0.65      0.64      0.64       363\n",
      "weighted avg       0.65      0.64      0.64       363\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f88a6fdbc88>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcFNW5//HP0zOAA8MiIAZFBVQgEsQFDS4XURCMG2gSNcENRVxBNCqiXEWNUYNEo4kmiFeJkrii3osr+pMoiQYRQVGMSkREdhhWWWbg+f3RBRkJzNT0dHVVN9/363Ve3XWqq+qZmubhzKlTp8zdERGR6KTiDkBEpNAp0YqIREyJVkQkYkq0IiIRU6IVEYmYEq2ISMSUaEVEIqZEKyISMSVaEZGIFUd9gBFmuvUsYjcv+yjuEAqeFZXEHcLOofG+Vttd1CTnjHCv9fHCUItWRCRikbdoRURyKYmtRyVaESkoRXEHsB1KtCJSUNSiFRGJWE6ubtWQEq2IFBS1aEVEIqYWrYhIxNSiFRGJmEYdiIhETC1aEZGIKdGKiERMF8NERCKmFq2ISMR0MUxEJGJq0YqIREx9tCIiEVOLVkQkYkq0IiIRU9eBiEjEkpjUkhiTiEjG1KIVEYmY+mhFRCKmFq2ISMTUohURiZhuwRURiZhatCIiEVOiFRGJWLYuhplZe+DJSlVtgZuAJsBFwJKg/gZ3f6mqfSnRikhBsVR2Uq27/xM4CMDMioBvgOeA/sA97n532H0p0YpIQTGLZIBXD2C2u3+Vyf6T2J0hIpKxoqJU6FIDZwF/qbR8hZl9aGb/Y2a7VrfxTt+i7TpkCIcMGADuLProI17o35+T//AH9jnmGDasXAnA8+efz8IZM2KOND8tWLSUobfex9JlK0iljDP6HM+5Z57Mr+8fy5uTp1KnTjF77/k9fjX8Cho1bBB3uHlrwaIlXDdiFEuXlZEy44zTTuC8s/qyYuVqrrrxDr5ZsJg9W7bg3l8No3GjhnGHG6madB2Y2UBgYKWq0e4+epvP1AVOBYYFVQ8CtwEevI4CLqjyOO4eOqhMjDCL9gC10HCPPbhg8mR+f8ABVKxfz0+ffJLPX3qJ1t2789mECXzy7LNxhxjKzcs+ijuEHVq8tIwly8ro2L4ta9au48f9r+X3dw1l4eJldD20E8XFRdz9+8cAuObyc2KOdsesqCTuEKq0eOlylixdTscO+7Fm7bf8+NzB/H7kTYyfMJEmjRsy8LwzGD32KVauWsO1g6rMCfFqvG+t/+6fWL9e6Jxz/Lcbqj2emfUBLnf3XttZ1xqY4O4/qGofO33XQaq4mDolJaSKiqhTvz6r58+PO6SC0qL5rnRs3xaA0gYl7Nu6FYuWLOfoHx5EcXF6aHnnju1YuHhZnGHmvRbNm9Kxw34AlDaoT9s2e7NoyVLeeOtd+p7UE4C+J/Xk9b++E2eYOWEpC11C+hmVug3MrGWldacBM6vbQehEa2b7mFnP4H2JmeX93x+r58/n73ffzVVz5/KLBQtYv3IlsydOBOC422/n0hkz6P2b31BUt27MkRaGeQsWM+uzL+nccf/v1D874Q26HXFwTFEVnnnzFzHrn7Pp3LEDy5avoEXzpkA6GS8vWxlzdNEzs9AlxL7qA8cD4ytV/9rMPjKzD4Fjgauq20+oRGtmFwHPAH8MqloBz4fZNsl2adKEDn36cG+bNozaYw/qNmjAgf368fqwYfyuQwdGH3YYJU2bcvTQoXGHmvfWfruOwcNGMmxIf0ob1N9a/4dHn6G4qIhTeneLMbrCsfbbdQy+/nZuuHogpaX1q9+gAGWzRevu37p7M3dfWanuHHfv5O4Huvup7r6guv2EbdFeDhwFrAoO9DnQYkcfNrOBZjbVzKa+H/IAcWjbsydlX37Jt0uXsrmiglnjx7PXkUeyZuFCADZt3Mj0Rx5hz8MPjznS/FZeUcHgG0ZySu//olf3rlvrn3vxTd782/uMvGVIVENydirlFRUMHno7p/TuTq9jjwKgWdMmLF66HEj34zbdtXGcIeZERKMOaiXskTa4+8YtC2ZWTPqK23a5+2h37+LuXQ6tbYQRWjl3Lq26dqVOSfpCR5sePVgyaxal3/ve1s906NuXxTOr7YKRHXB3ht/+APvu04r+Pzt1a/3b73zAmMef58FfX0/JLvVijLAwuDs33nYvbdvsRf9+p2+tP65bV55/8XUAnn/xdXp067qjXRSMbHYdZC2mMKMOzOzXwArgXGAQcBnwibvfWN22SR51ANB9xAh+cOaZbK6oYMEHH/C/AwZw9ssvU3+33TAzFk6fzoRLLmHj2rVxh7pDSR518P6MWfS7ZDjt9t2bVCr9//pVl/yc23/zP2wsL6dJ43RXf+eO7bhl6MVxhlqlpI86mDr9Y/oNvJZ2+7UmZenzfPVl53Fgx/YMueEOFixaQsvdd+O3d9yw9ZwnUhZGHby9W6PQOee/lqzKSbYNm2hTwIVAL9K3Er8KjPEQGyc90RaCJCfaQpH0RFswspBoJ7doHDrnHL14ZU4SbdgbFvoAf3L3h6IMRkSktrI110E2he2jPRX4zMweM7OTgj5aEZHESRWlQpecxRTmQ+7eH9gPeBr4OTDbzMZEGZiISCaSeDEsdMvU3cvN7GXSow1KSHcnDIgqMBGRTKTytevAzE4ws0eBL4CfAGOAllVuJCISg3xu0Z4PPAFc7O4bogtHRKR2kngxLFSidfezog5ERCQbkniXYZWJ1swmu/vRZraa794JZoC7e6NIoxMRqaFUUZ4lWnc/OnhN8K0kIiL/lsSug7AXwx4LUyciEreUWeiSK2EvhnWsvBDcsJDk+WJEZCeVdy1aMxsW9M8eaGargrIaWAS8kJMIRURqIInDu6pMtO5+R9A/O9LdGwWlYTAR7rCqthURiUMEj7KptbDDu4YFj9TdH9ilUv1bUQUmIpKJXM5hEFaoRGtmA4ArST/CZjrQFXgHOC660EREai6J42jDpv4rgcOAr9z9WOBgYElkUYmIZMhSqdAlV8KOOljv7uuDDuR67v6pmbWPNDIRkQwkcdRB2EQ7z8yakH7y7UQzKwPmRxeWiEiGEth1EPZi2GnB2xFm9ibQGHglsqhERDKUKi6KO4T/EPZiWNNKi1seUKVngYlI4iTxYljYroNpwF5AGekJZZoAC8xsMXCRu78fUXwiIjWTwD7asJfdXgFOdPfm7t4M+BHwFOnHjj8QVXAiIjWVxFEHYY/Uxd1f3bLg7q8B3dz9XaBeJJGJiGQgibfghu06WG5mQ0k/ZQHgTKDMzIqAzZFEJiKSgXwe3vVz4GbSw7sAJgd1RcAZEcQlIpIRK8rTUQfuvhQYZGal7r5mm9VfZD8sEZHMJLFFG3bi7yPN7BPgk2C5s5npIpiIJE4SZ+8KezHsHqA3sAzA3WcA3aIKSkQkY5YKX3IkbB8t7v71NlfpNmU/HBGR2kli10HYRPu1mR0JuJnVBQYDs6ILS0QkM/mcaC8BfgvsCcwDXgMujyooEZFM5fuog36ZHGDEuqWZbCY1cF9J87hDKHiDyj6NO4SdQjbaonnXojWzm6pY7e5+W5bjERGplXycVGbtduoaABcCzQAlWhFJlFzOYRBWlYnW3UdteW9mDUk/0qY/6VtxR+1oOxGRuGSz6yB44MEY4Aekp4a9APgn8CTQGpgDnOHuZVXtp9rUb2ZNzeyXwIekE/Mh7j7U3RfX5gcQEYmCFaVClxB+C7zi7h2AzqRHW10PvOHu+wNvBMtVqq6PdiRwOjAa6LSd229FRBIlW10HZtaI9I1Z5wO4+0Zgo5n1AboHHxsLTAKGVrWv6iL6BbAHMByYb2argrLazFZl+gOIiEQli9MktiX9tO9HzOwDMxtjZg2A3d19AUDw2qK6HVWZaN095e4l7t7Q3RtVKg3dvVG4H1tEJIdSFrqY2UAzm1qpDKy0p2LgEOBBdz+Y9OCAarsJtif0LbgiIvmgJl0H7j6adNfo9swD5rn7P4LlZ0gn2kVm1tLdF5hZS6Da61XJGwchIlIL2eo6cPeFpKcfaB9U9SA9g+H/AucFdecBL1QXk1q0IlJQQo4mCGsQMC6Y4+VfpIe3poCnzOxCYC7w0+p2okQrIgUlm+No3X060GU7q3rUZD9KtCJSWJJ3B64SrYgUmDyc60BEJK8kMM8q0YpIYbGi5GVaJVoRKSwJbNIq0YpIYUng3QFKtCJSUPJx4m8RkfyiRCsiEq0E5lklWhEpMBp1ICISLfXRiohELXl5VolWRApLNieVyRYlWhEpLMnLs0q0IlJg1EcrIhItzXUgIhKxBDZolWhFpMAkMNMq0YpIQUlgnlWiFZECo+FdyTPsptuZ9NbfaNZ0VyaMH7e1/rE/P83jTzxLcVERx3Q7kuuuujzGKPPbQUOG0HHAAHBn6Ucf8Xr//vR4+GF279KFzeXlLJwyhTcvvpjNFRVxh5q3FixawtAR97J0eRkpM87o25tzzzqVV96YzO8e+guz58zjqUfuptP394871MglcRxtAmduzK3T+5zImAfv+U7du1Pe541Jb/N/z/yJF58bx4Xn/iym6PJfgz32oPPgwTzRpQvjOnUiVVREu7PO4p/jxvFYhw6M69SJ4pKSdCKWjBUVFTH0ygt46ckHeOLhkYx75iW++Ndc9m+7D/fdNYwuB3eMO8TcMQtfcmSnb9EedujBzPtmwXfq/vL0cwy84Bzq1q0LQLNmTeMIrWCkiospLilhc3k5xfXrs3b+fOZOnLh1/aIpUyht1SrGCPNfi+ZNadE8/T0tbVCffVu3YtGSZRz1w4Njjiz3LIHNxypDMrOmVZVcBZlrc776mqnTZvDTfgM4+4LL+HDmJ3GHlLfWzp/PtLvvpv/cuQxYsIANK1d+J8mmiovpcM45fPXKKzFGWVjmzV/ErM/+ReeO7eMOJR4JbNFWl/vfB6YGr9uWqdGGFp9NFRWsWrWKpx5/iOuuuoIh1/437h53WHmpXpMmtO3Th7Ft2vDwHntQp0ED2vfrt3V99wce4Ju33mL+5MkxRlk41n67jsHX38mwqwZQWlo/7nDiYTUoOVJlonX3Nu7eNnjdtrTd0XZmNtDMpprZ1NEPj81+1BHbffcWHN+jO2bGgZ0OIJUyyspWxB1WXtqrZ09Wffkl65YuZXNFBbPHj6flkUcCcPhNN1Gy2268ffXVMUdZGMorKhh8/Z2ccsIx9Dr2yLjDiY2ZhS65ErqP1sx2BfYHdtlS5+5vbe+z7j4aGA3A+mV51xTseWw33p3yPj887BC+nDOX8vIKdt21Sdxh5aXVc+fyva5dKS4poWLdOvbq0YNFU6fS8cIL2ad3b8b36AH6a6HW3J3hv7yffVu3ov/P+8YdTryKktdJGyrRmtkA4EqgFTAd6Aq8AxwXXWi5cfXQm5gy9QPKVqyg2/F9GHTpAH582snccNPtnHx6P+rUqcOdtw1P5GTC+WDRlCl88cwznDVtGl5RwZIPPuDj0aO5dO1aVn/1FWe88w4As8ePZ8ptt8Ucbf6aNmMWL7z8Ju3224e+Z18JwFWXnsPG8nJ+efdolq9YySVX3UqHdm15+L5bYo42Ygkc3mVh+h7N7CPgMOBddz/IzDoAt7j7mdVunIct2nxzX0nzuEMoeIPKPo07hJ2CNWlf6yy56f7zQuecokFjc5KVw3YdrHf39UG/Rj13/9TMdtJLmiKSaAn86zNsop1nZk2A54GJZlYGzI8uLBGRDCWw6yBUonX304K3I8zsTaAxoIGPIpI8CbxjodpEa2Yp4EN3/wGAu/818qhERDKVj6MO3H2zmc0ws73dfW4ughIRyVgqDxNtoCXwsZlNAdZuqXT3UyOJSkQkU3l8MazAB96JSMHI4xbtie4+tHKFmd0FqL9WRJIlgS3asKn/+O3U/SibgYiIZEVRUfiSI1W2aM3sUuAyYF8z+7DSqobA36MMTEQkIwls0VbXdfBn4GXgDuD6SvWr3X15ZFGJiGQo24+yMbMi0tPCfuPuJ5vZo8AxwMrgI+e7+/Sq9lFlonX3lcBKMxu6zapSMyvVcC8RSZzs37BwJTALaFSp7lp3fybsDsJeDHsRcNJT5e4CtAH+CexEDyISkbyQxRatmbUCTgJuBzKeODlU6nf3Tu5+YPC6P3A4oCnxRSR5avAom8oPKQjKwG32di9wHbB5m/rbzexDM7vHzOpVF1JGD2d092lmdlgm24qIRKoGowm+85CCbZjZycBid3/fzLpXWjUMWAjUDbYdCtxa1XHCTvxducmcAg4BloTZVkQkp7I36uAo4FQzO5F0l2kjM3vc3c8O1m8ws0eAa6rbUdhe44aVSj3SfbZ9ahy2iEjUUqnwpQruPszdW7l7a+As4P+5+9lm1hLA0o9d6QvMrC6ksNMk3hLsuIG7r63u8yIisYl+HO04M9uN9OCA6cAl1W0QtuvgCOBhoBTY28w6Axe7+2W1CFZEJPsimPjb3ScBk4L3NX5WYtiug3uB3sCy4EAzgG41PZiISOQsFb7kSOhRB+7+9TZPgt2U/XBERGopHyf+DnxtZkcCbmZ1gcGk75QQEUmWBE6TGDaiS4DLgT2BecBBwbKISLLU4IaFXAk76mAp0C/iWEREai/fZu8ys5uqWO3ufluW4xERqZ08fAru9sbMNgAuBJoBSrQikiwRDO+qreqmSRy15b2ZNSQ9XVh/4Alg1I62ExGJTb51HQCYWVPS04P1A8YCh7h7WdSBiYhkJN8SrZmNBE4nPUNNJ3dfk5OoREQylrxEW12v8S+APYDhwHwzWxWU1Wa2KvrwRERqyGpQcqS6PtrkXb4TEalKvnUdiIjknQTeGRZ9onVNiRC1K2Y+EncIBe/z40+MO4SdQrv3ZmdhL2rRiohEK3l5VolWRAqM+mhFRCKmRCsiErE8nOtARCS/qEUrIhKx5OVZJVoRKTBq0YqIRE2JVkQkWmrRiohELN8m/hYRyTtq0YqIRE2JVkQkWmrRiohETIlWRCRiSrQiIhFTohURiZgSrYhIxJRoRUSipkQrIhIttWhFRCJmRXFH8B+UaEWksKhFKyISMT3KRkQkaslr0SYv9YuI1IZZ+FLlbmwXM5tiZjPM7GMzuyWob2Nm/zCzz83sSTOrW11ISrQiUmBSNShV2gAc5+6dgYOAE8ysK3AXcI+77w+UAReGiUhEpHCkUuFLFTxtTbBYJygOHAc8E9SPBfpWG1LmP42ISBJZDUo1ezIrMrPpwGJgIjAbWOHuFcFH5gF7VrcfJVoRKSyWCl3MbKCZTa1UBlbelbtvcveDgFbA4cD3t3NEry4kjToQkcJSg3G07j4aGB3icyvMbBLQFWhiZsVBq7YVML+67dWiFZECk52uAzPbzcyaBO9LgJ7ALOBN4CfBx84DXqguop2+RTvs5juY9NbfadZ0VyY8+ycAhlx3M1/OmQvA6tVraNiwlBeeeiTOMPPaho0VnDP8cTaWb6Ji82Z6H9GeQWd148bfv8jHXyzEcVq3bMqvBp1Mg5JqR8rIDqRKG7L78Duot2873J1Ft13Prj/rT5192gBQVNqITWtWMbffKTFHGrHs3bDQEhhrZkWkG6VPufsEM/sEeMLMfgl8ADxcbUju1XYv1M66xREfoHbee3869euXMHT47VsTbWV3jvodpaUNuOLi/jFEF87mf70UdwhVcne+XV9Og5K6lFds4uwbH2PYBcez317NKa1fD4A7H3mdZo0bcNHpR8Qc7fZ9cf5tcYdQrd1vHsm66e+x6oWnoLgOqV12YfOa1VvXNx8yjM1rVrN8zO9ijLJq7d6bXeu7DXzOS6FzjrU+MSd3N+z0XQeHHXoQjRs12u46d+fl197k5BN65jiqwmJmW1uqFZs2U16xGTO2Jll3Z/3Giqp2IdVINSil/sGHpZMsQEX5d5IsQMOeJ7H61QkxRJdjNbgYliuhuw7MbB9gf3d/PeivKHb31dVtl8+mTptBs2a70nqfveIOJe9t2rSZn1z7CHMXlvGzEw6lc7v0iJgb7p/AW9Nms+9ezRl6fo+Yo8xfdfbci00rlrP7zb+m3v4d2DBrJotH3YavXwdAycGHsWnZUsq/nhNvoDmRp7fgmtlFpAfo/jGoagU8H1VQSTHhldfVms2SoqIUz/3mQt586Ao++mI+n321BIBfDTqZv44ZRNs9m/Hy5FkxR5nHioqp174jK58Zx9yzT2Xz+nU0Pf+Srasb9jqF1a/9X4wB5lCWbsHNprBt58uBo4BVAO7+OdBiRx+uPDZt9MP/2e+ZDyoqKpj4xluc2Pu4uEMpKI0a7MLhHfdm8gf/2lpXVJTiR0cfwGvvfhpjZPmtYvECKhYvZP3HMwBY88bL1GvfMb2yqIjSY3uzeuKLMUaYQwnsOgh7pA3uvnHLgpkVU8UgXXcf7e5d3L3LwAvPrW2Msfj7P96nbZu9+d7uO/z/REJavvJbVq1dD8D6DeW88+Ec2uzZlK8WLAfSfbST3vuctns2izPMvLZp2VLKFy3YOsKg/mFHsvHLL9LvDz+KjV/NpmLxwjhDzJ0EJtqwfbR/NbMbgBIzOx64DCiIv0Ouvn4EU6Z+QNmKlXTrdTqDLr2An552Mi+98jonqdsgK5aUrWHY/RPYtHkzmzc7Jxz1fY45dD/OvvEx1qzbiLvToXULbr74hLhDzWtL7r6Flrfeg9WpQ/k3X7Pw1usAaNjrZFa/WhD/XMNJ4Hy0oYZ3mVmK9Aw1vUj3NL8KjPEwGyd8eFchSPrwrkKQD8O7CkFWhnd989fww7v2PCYnHbVhW7R9gD+5+0NRBiMiUmsJfJRN2Db2qcBnZvaYmZ0U9NGKiCRQ1uajzWpE1XL3/sB+wNPAz4HZZjYmysBERDKSwOFdoVum7l5uZi+THm1QQro7YUBUgYmIZCSBjxsPe8PCCWb2KPAF6VlrxpCecEFEJFnyuEV7PvAEcLG7b4guHBGR2krexbBQidbdz4o6EBGRrEjgqIMqE62ZTXb3o81sNd+9E8xIP7ts+9NeiYjEJs8SrbsfHbw2zE04IiK1lMAWbdiLYY+FqRMRiZ0VhS85EvZiWMfKC8ENC4dmPxwRkdrKsxatmQ0L+mcPNLNVQVkNLCLEA8lERHIugcO7qky07n5H0D870t0bBaWhuzdz92E5ilFEpAay8xTcbKpu1EEHd/8UeNrMDtl2vbtPiywyEZFMJPBiWHV9tFcDA4FR21nngB4/ICLJksD5aKsb3jUweD02N+GIiNRW8hJt2OFdPzWzhsH74WY23swOjjY0EZEM5NvFsEr+291Xm9nRQG9gLPCH6MISEclU8i6GhU20m4LXk4AH3f0FoG40IYmI1EbyEm3YGxa+MbM/Aj2Bu8ysHknsCBGRnZ4lcNRB2GR5BukHMp7g7iuApsC1kUUlIpKpfH3cuLt/a2azgd5m1ht4291fizY0EZFM5GmL1syuBMYBLYLyuJkNijIwEZGM5GuLFrgQ+KG7rwUws7uAd4D7owpMRCQzyWvRhk20xr9HHhC8T95PIyKSwIthYRPtI8A/zOy5YLkv8HA0IYmI1EaeJlp3/42ZTQKOJv1T9Hf3D6IMTEQkI/k214GZ7QJcAuwHfAQ84O4VuQhMRCQjedh1MBYoB94GfgR8HxgSdVAiIpnLv0R7gLt3AjCzh4Ep0YckIlIL+dZ1QLo1C4C7VyTx1jYRke9KXp6qLtF2NrNVwXsDSoJlA9zdG0UanYhITSWwRWvuHncMiWNmA919dNxxFDKd4+jpHCdH8lJ/MgyMO4CdgM5x9HSOE0KJVkQkYkq0IiIRU6LdPvVrRU/nOHo6xwmhi2EiIhFTi1ZEJGJ5nWjNzM1sVKXla8xsRATHuWGb5b9n+xj5JJvn3cyamNllGW47x8yaZ7JtkpnZJjObbmYzzexpM6ufwT7GmNkBwXt9f2OW14kW2ACcnoN/bN/5orr7kREfL+myed6bANtNtGZWlIX956N17n6Qu/8A2Eh6YqcacfcB7v5JsKjvb8zyPdFWkO7wv2rbFWa2m5k9a2bvBeWoSvUTzWyamf3RzL7akjDM7Hkze9/MPjazgUHdnaTviJtuZuOCujXB65NmdmKlYz5qZj82syIzGxkc90MzuzjyM5FbmZz3EWZ2TaXPzTSz1sCdwL7B+R1pZt3N7E0z+zPpGeO2+3vZibxNevY8zOzq4LzNNLMhQV0DM3vRzGYE9WcG9ZPMrIu+vwnh7nlbgDVAI2AO0Bi4BhgRrPszcHTwfm9gVvD+d8Cw4P0JgAPNg+WmwWsJMBNotuU42x43eD0NGBu8rwt8HWw7EBge1NcDpgJt4j5fMZ/3EcA1lfYxE2gdlJmV6rsDayufryp+L3O2/O4KqVT6fhUDLwCXAoeS/o+nAVAKfAwcDPwYeKjSto2D10lAF31/k1HCPmEhsdx9lZn9CRgMrKu0qidwQKWJcBqZWUPSk5efFmz7ipmVVdpmsJmdFrzfC9gfWFbF4V8G7jOzeqST9lvuvs7MegEHmtlPgs81Dvb1ZaY/Z9JkcN5rYoq7Vz5XNf295LsSM5sevH+b9NNMLgWe838/t2888F/AK8DdwXP8Jrj72zU4zk77/c21vE+0gXuBaaQfubNFCjjC3SsnAWwHU5CZWXfSSeIITz9efRKwS1UHdff1wed6A2cCf9myO2CQu79a458kv9TkvFfw3a6qqs7t2krbdaeGv5cCsM7dD6pcsaPvrbt/ZmaHAicCd5jZa+5+a5iD6PubO/neRwuAuy8HniL9tN4tXgOu2LJgZlu+uJOBM4K6XsCuQX1joCz4x9wB6FppX+VmVmcHh38C6E+6dbHli/kqcOmWbcysnZk1yPDHS6wanvc5wCFB3SFAm6B+NVBVi7eq38vO5C2gr5nVD75LpwFvm9kewLfu/jhwN8E53oa+vzEriEQbGAVUvgo+GOgSdOZ/wr+v3N4C9DKzaaSfGrGA9D/2V4BiM/sQuA14t9K+RgMfbrmYsI3XgG7A6+6+MagbA3wCTDOzmcAfKZy/HrYV9rw/CzQN/iS+FPgMwN2XAX8LLuSM3M7+q/q97DTcfRrwKOnJ9/8BjPH0c/s6AVOC83oj8MvtbK7vb8x2ujvDgv6oTZ6eyPwI4MFt/0xpYdn5AAAAR0lEQVQTEcmmnfF/qb2Bp8wsRXqM4kUxxyMiBW6na9GKiORaIfXRiogkkhKtiEjElGhFRCKmRCsiEjElWhGRiCnRiohE7P8D5R5midDvkEkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = clf.predict(x_validation_data)\n",
    "print(classification_report(y_validation_data, prediction))\n",
    "\n",
    "df_cm = confusion_matrix(y_validation_data, prediction)\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "sns.heatmap(df_cm, annot=True,cmap=\"OrRd\", xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, it can be seen that the most common misclassification is labelling positive titles as neutral. The accuracy was around 64 %. Next, the performance is analysed using the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison using the whole dataset instead of smaller, normalized one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning:\n",
      "\n",
      "You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "\n",
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning:\n",
      "\n",
      "max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7438080495356038\n",
      "{'clf-svm__alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Test and validation data creation\n",
    "feature1 = df[\"title\"]\n",
    "feature2 = df[\"sentiment\"]\n",
    "\n",
    "x_training_data, x_validation_data, y_training_data, y_validation_data = train_test_split(feature1, feature2, test_size=0.2, random_state=0) \n",
    "\n",
    "# Trainining the model and optimizing hyperparameters\n",
    "\n",
    "parameters = {}\n",
    "parameters['clf-svm__alpha'] = [0.001, 0.0005, 0.0001]\n",
    "\n",
    "clf2 = GridSearchCV(sgd_classifier_model, parameters)\n",
    "clf2.fit(x_training_data, y_training_data)\n",
    "print(clf2.best_score_)    \n",
    "print(clf2.best_params_)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.36      0.48       121\n",
      "     neutral       0.71      0.92      0.80       553\n",
      "    positive       0.72      0.46      0.56       296\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       970\n",
      "   macro avg       0.72      0.58      0.62       970\n",
      "weighted avg       0.71      0.71      0.69       970\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f88829fc6a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = clf2.predict(x_validation_data)\n",
    "print(classification_report(y_validation_data, prediction))\n",
    "\n",
    "df_cm = confusion_matrix(y_validation_data, prediction)\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "sns.heatmap(df_cm, annot=True,cmap=\"OrRd\", xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the whole dataset was used without normalizing it so that each category had an equal amount of samples. As a result, the accuracy increased to 74 %. However, this caused titles with neutral sentiment to dominte the other categories, decreasing the recall of negative and positive titles. As can be seen from the confusion matrix, negative labels are very poorly detected, and also less than half of positive ones are detected correctly. As a conclusion, such model was not considered optimal for the use case, and the model with lower accuracy was chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing for LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second model, LSTM was chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation\n",
    "df2 = df[[\"title\",\"sentiment\"]] \n",
    "df2.columns = ['text', 'target']\n",
    "df2[['target']] = df2[['target']].replace([\"positive\",\"neutral\",\"negative\"], [2, 1, 0])\n",
    "df2 = df2[df2['text'].map(len) > 10]\n",
    "train_df, valid_df = train_test_split(df2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = word_tokenize, include_lengths = True)\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://gist.github.com/lextoumbourou/8f90313cbc3598ffbabeeaa1741a11c8\n",
    "# to use DataFrame as a Data source\n",
    "\n",
    "class DataFrameDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, df, fields, is_test=False, **kwargs):\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.target if not is_test else None\n",
    "            text = row.text\n",
    "            examples.append(data.Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, fields, train_df, val_df=None, test_df=None, **kwargs):\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "        data_field = fields\n",
    "\n",
    "        if train_df is not None:\n",
    "            train_data = cls(train_df.copy(), data_field, **kwargs)\n",
    "        if val_df is not None:\n",
    "            val_data = cls(val_df.copy(), data_field, **kwargs)\n",
    "        if test_df is not None:\n",
    "            test_data = cls(test_df.copy(), data_field, True, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('text',TEXT), ('label',LABEL)]\n",
    "\n",
    "train_ds, val_ds = DataFrameDataset.splits(fields, train_df=train_df, val_df=valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                               \n",
      "100%|█████████▉| 399332/400000 [00:55<00:00, 7629.45it/s]"
     ]
    }
   ],
   "source": [
    "# Build vocabulary using GloVe\n",
    "MAX_VOCAB_SIZE = 25000\n",
    "\n",
    "TEXT.build_vocab(train_ds, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = 'glove.6B.200d',\n",
    "                 unk_init = torch.Tensor.zero_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 (LSTM) Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model relies heavily on the following Kaggle notebook: https://www.kaggle.com/swarnabha/pytorch-text-classification-torchtext-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator = data.BucketIterator.splits(\n",
    "    (train_ds, val_ds), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_within_batch = True,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 25\n",
    "learning_rate = 0.001\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 200\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)       \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        embedded = self.embedding(text)\n",
    " \n",
    "        #pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        output = self.fc1(hidden)\n",
    "        output = self.dropout(self.fc2(output))\n",
    "                \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the LSTM_net class\n",
    "model = LSTM_net(INPUT_DIM, \n",
    "            EMBEDDING_DIM, \n",
    "            HIDDEN_DIM, \n",
    "            OUTPUT_DIM, \n",
    "            N_LAYERS, \n",
    "            BIDIRECTIONAL, \n",
    "            DROPOUT, \n",
    "            PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7579, 200])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1189,  0.1599, -0.2332,  ...,  0.6788,  0.9448,  0.3268],\n",
       "        ...,\n",
       "        [ 0.1892,  0.0165,  0.5557,  ...,  0.6909, -0.2369,  0.7791],\n",
       "        [-0.5785,  0.1491,  0.0510,  ...,  0.1844,  0.2903,  0.2528],\n",
       "        [-0.0364, -0.4738, -0.1913,  ...,  0.4871, -0.0841,  0.5200]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1189,  0.1599, -0.2332,  ...,  0.6788,  0.9448,  0.3268],\n",
      "        ...,\n",
      "        [ 0.1892,  0.0165,  0.5557,  ...,  0.6909, -0.2369,  0.7791],\n",
      "        [-0.5785,  0.1491,  0.0510,  ...,  0.1844,  0.2903,  0.2528],\n",
      "        [-0.0364, -0.4738, -0.1913,  ...,  0.4871, -0.0841,  0.5200]])\n"
     ]
    }
   ],
   "source": [
    "# Initiaise padded to zeros\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        text, text_lengths = batch.text\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399332/400000 [01:10<00:00, 7629.45it/s]"
     ]
    }
   ],
   "source": [
    "def evaluate(model, iterator):\n",
    "    \n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            \n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: -20.621 | Train Acc: 57.05%\n",
      "\t Val. Acc: 64.18%\n",
      "\tTrain Loss: -66.958 | Train Acc: 61.67%\n",
      "\t Val. Acc: 60.97%\n",
      "\tTrain Loss: -178.144 | Train Acc: 59.40%\n",
      "\t Val. Acc: 60.46%\n",
      "\tTrain Loss: -326.159 | Train Acc: 61.91%\n",
      "\t Val. Acc: 62.01%\n",
      "\tTrain Loss: -676.606 | Train Acc: 64.39%\n",
      "\t Val. Acc: 63.84%\n",
      "\tTrain Loss: -1066.460 | Train Acc: 59.48%\n",
      "\t Val. Acc: 59.04%\n",
      "\tTrain Loss: -1488.934 | Train Acc: 63.95%\n",
      "\t Val. Acc: 58.31%\n",
      "\tTrain Loss: -1678.587 | Train Acc: 64.20%\n",
      "\t Val. Acc: 64.49%\n",
      "\tTrain Loss: -2620.654 | Train Acc: 64.81%\n",
      "\t Val. Acc: 40.65%\n",
      "\tTrain Loss: -3105.650 | Train Acc: 60.74%\n",
      "\t Val. Acc: 48.23%\n",
      "\tTrain Loss: -3575.702 | Train Acc: 64.08%\n",
      "\t Val. Acc: 51.69%\n",
      "\tTrain Loss: -4368.822 | Train Acc: 62.08%\n",
      "\t Val. Acc: 57.65%\n",
      "\tTrain Loss: -5579.807 | Train Acc: 64.33%\n",
      "\t Val. Acc: 60.91%\n",
      "\tTrain Loss: -6598.165 | Train Acc: 64.11%\n",
      "\t Val. Acc: 60.34%\n",
      "\tTrain Loss: -7444.642 | Train Acc: 65.24%\n",
      "\t Val. Acc: 61.73%\n",
      "\tTrain Loss: -8431.545 | Train Acc: 65.47%\n",
      "\t Val. Acc: 59.02%\n",
      "\tTrain Loss: -10319.307 | Train Acc: 67.15%\n",
      "\t Val. Acc: 62.73%\n",
      "\tTrain Loss: -11796.610 | Train Acc: 67.71%\n",
      "\t Val. Acc: 57.57%\n",
      "\tTrain Loss: -12952.104 | Train Acc: 67.49%\n",
      "\t Val. Acc: 62.10%\n",
      "\tTrain Loss: -11968.243 | Train Acc: 59.75%\n",
      "\t Val. Acc: 62.28%\n",
      "\tTrain Loss: -13287.894 | Train Acc: 63.01%\n",
      "\t Val. Acc: 58.14%\n",
      "\tTrain Loss: -15587.545 | Train Acc: 63.96%\n",
      "\t Val. Acc: 54.23%\n",
      "\tTrain Loss: -16628.768 | Train Acc: 64.28%\n",
      "\t Val. Acc: 61.71%\n",
      "\tTrain Loss: -17353.512 | Train Acc: 64.53%\n",
      "\t Val. Acc: 57.18%\n",
      "\tTrain Loss: -18934.380 | Train Acc: 66.33%\n",
      "\t Val. Acc: 63.33%\n"
     ]
    }
   ],
   "source": [
    "loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator)\n",
    "    valid_acc = evaluate(model, valid_iterator)\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    loss.append(train_loss)\n",
    "    acc.append(train_acc)\n",
    "    val_acc.append(valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the training accuracy is about 66 %, and the validation accuracy is around 63 %. Most likely there isn't any remarkable under- or overfitting. The low accuracy can be explained at least partially by the small amount of data as well as the misclassified samples that were detected previously in the initial data exploration phase. Only under 5000 data points were used for this task. It is worth noticing that while the previous SGDClassifier had a normalized dataset containing 604 titles for each category, this model was trained with all the available datapoints.\n",
    "\n",
    "As a conclusion, due to the increased complexity, poor performance, and high computational expense, SGDClassifier was chosen as the final, deployable model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['production_model_SGDClassifier.pkl']"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "from sklearn.externals import joblib \n",
    "joblib_file = \"production_model_SGDClassifier.pkl\"   \n",
    "joblib.dump(clf, joblib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "production_model_SGDClassifier.pkl\n"
     ]
    }
   ],
   "source": [
    "!mkdir model-dir\n",
    "!cp production_model_SGDClassifier.pkl model-dir\n",
    "!tar -zcvf production_model_SGDClassifier.tar.gz production_model_SGDClassifier.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "client = WatsonMachineLearningAPIClient( {\n",
    "  \"apikey\": \"REMOVED\",\n",
    "  \"iam_apikey_description\": \"REMOVED\",\n",
    "  \"iam_apikey_name\": \"REMOVED\",\n",
    "  \"iam_role_crn\": \"REMOVED\",\n",
    "  \"iam_serviceid_crn\": \"REMOVED\",\n",
    "  \"instance_id\": \"REMOVED\",\n",
    "  \"url\": \"REMOVED\"\n",
    "} )\n",
    "pipeline = joblib.load( \"production_model_SGDClassifier.pkl\")\n",
    "model_details = client.repository.store_model( pipeline, \"My scikit-learn model (in-memory object)\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: 'e5195880-088a-478a-9f17-8183b0f4c75b' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "INITIALIZING\n",
      "DEPLOY_SUCCESS\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='eb52acdb-b151-4c86-b150-845fef367084'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_id = model_details[\"metadata\"][\"guid\"]\n",
    "model_deployment_details = client.deployments.create( artifact_uid=model_id, name=\"SVM sentiment analysis model deployment\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://us-south.ml.cloud.ibm.com/v3/wml_instances/4a4e4888-e056-4b13-b540-d8d10e4ff354/deployments/eb52acdb-b151-4c86-b150-845fef367084/online'"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_endpoint_url = client.deployments.get_scoring_url( model_deployment_details )\n",
    "model_endpoint_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['prediction', 'probability'],\n",
       " 'values': [['neutral',\n",
       "   [0.2311133110833331, 0.44926031477886685, 0.3196263741378001]]]}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_endpoint = \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/4a4e4888-e056-4b13-b540-d8d10e4ff354/deployments/eb52acdb-b151-4c86-b150-845fef367084/online\"\n",
    "payload_scoring = {'fields': [\"title\"], \n",
    "                   'values': [[\"No surprises in Apple's revenue\"]]}\n",
    "client.deployments.score(scoring_endpoint,payload_scoring)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
